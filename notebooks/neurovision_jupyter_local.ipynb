{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f68d0c-a42d-4ede-a02d-d2ea6dbf9275",
   "metadata": {},
   "source": [
    "# NeuroVision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162949c-6fe9-43c2-a775-7dbf886ab75a",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fce1e7a-a9dd-47e5-970b-682938b29ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbc4228-6ab9-4fb4-8dbc-13d2b07e5d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read the dir contents of dataset folder and segregate them \n",
    "# into n separate classes.\n",
    "def create_dataset_folders(metadata_file:str, csv_dir:str, output_dir:str):\n",
    "    class_id_to_folder = {}\n",
    "\n",
    "    with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "\n",
    "            label_str, _, class_id = parts\n",
    "            # print(label_str, class_id)\n",
    "            first_label = label_str.split(',')[0].strip()\n",
    "            # print(first_label)\n",
    "            class_id_to_folder[class_id] = first_label\n",
    "\n",
    "        count = 0\n",
    "        for filename in os.listdir(csv_dir):\n",
    "            if not filename.endswith('.csv'):\n",
    "                continue\n",
    "\n",
    "            class_id = filename.split('_')[3]\n",
    "\n",
    "            folder_name = class_id_to_folder.get(class_id)\n",
    "            print(folder_name)\n",
    "\n",
    "            if not folder_name:\n",
    "                print(f'Unknown class id: {class_id}')\n",
    "                continue\n",
    "\n",
    "            safe_folder = folder_name.replace('/', '_').replace('\\\\', '_').strip()\n",
    "\n",
    "            dest_folder = os.path.join(output_dir, safe_folder)\n",
    "            os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "            src_path = os.path.join(csv_dir, filename)\n",
    "            dst_path = os.path.join(dest_folder, filename)\n",
    "\n",
    "            # print(f\"Move: {src_path} to {dst_path}\")\n",
    "            count+=1\n",
    "            print(count)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee0ee6e-277d-43c4-8269-88ef54a61c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create_dataset_folders('../data/WordReport-v1.04.txt', \n",
    "#                        '../data/MindBigData-Imagenet', \n",
    "#                        '../data/Segregated_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc0b3cc-e26c-4823-8bd0-d3904f696b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import json\n",
    "import os\n",
    "\n",
    "def reorganize_dataset(mapping_file, src_root, dst_root, move=False):\n",
    "    with open(mapping_file, 'r') as f:\n",
    "        mapping = json.load(f)\n",
    "\n",
    "    os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "    for super_class, sub_classes in mapping.items():\n",
    "        super_cls_dir = os.path.join(dst_root, super_class)\n",
    "        os.makedirs(super_cls_dir, exist_ok=True)\n",
    "\n",
    "        for sub_class in sub_classes:\n",
    "            sub_cls_dir = os.path.join(src_root, sub_class)\n",
    "            if not os.path.exists(sub_cls_dir):\n",
    "                print(f\"[Warning] Sub-class folder not found: {sub_cls_dir}\")\n",
    "                continue\n",
    "\n",
    "            for file_name in os.listdir(sub_cls_dir):\n",
    "                src_file = os.path.join(sub_cls_dir, file_name)\n",
    "                dst_file = os.path.join(super_cls_dir, file_name)\n",
    "\n",
    "                if move:\n",
    "                    shutil.move(src_file, dst_file)\n",
    "\n",
    "                else: \n",
    "                    shutil.copy2(src_file, dst_file)\n",
    "\n",
    "            print(f\"[OK] {'Moved' if move else 'Copied'} {sub_class} -> {super_class}\")\n",
    "    print(\"Dataset reorganization complete!\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93d8148-91b6-47b6-890f-46ed86a39094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reorganize_dataset(mapping_file='../data/class_mapping_v4.json', \n",
    "#                    src_root='../data/Segregated_Dataset', \n",
    "#                    dst_root='../data/Classes_Regrouped_Dataset', \n",
    "#                    move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcbfb534-8949-47f3-ac56-937cd4528a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import json\n",
    "import os\n",
    "\n",
    "def reorganize_imagenet_dataset(mapping_file, src_root, dst_root, move=False):\n",
    "    with open(mapping_file, 'r') as f:\n",
    "        mapping = json.load(f)\n",
    "\n",
    "    os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "    for super_class, sub_classes in mapping.items():\n",
    "        super_cls_dir = os.path.join(dst_root, str(super_class).lower().replace(' ', '_').replace('-', '_'))\n",
    "        os.makedirs(super_cls_dir, exist_ok=True)\n",
    "\n",
    "        for sub_class in sub_classes:\n",
    "            sub_cls_dir = os.path.join(src_root, str(sub_class).lower().replace(' ', '_').replace('-', '_'))\n",
    "            if not os.path.exists(sub_cls_dir):\n",
    "                print(f\"[Warning] Sub-class folder not found: {sub_cls_dir}\")\n",
    "                continue\n",
    "\n",
    "            for file_name in os.listdir(sub_cls_dir):\n",
    "                src_file = os.path.join(sub_cls_dir, file_name)\n",
    "                dst_file = os.path.join(super_cls_dir, file_name)\n",
    "\n",
    "                if move:\n",
    "                    shutil.move(src_file, dst_file)\n",
    "\n",
    "                else: \n",
    "                    shutil.copy2(src_file, dst_file)\n",
    "\n",
    "            print(f\"[OK] {'Moved' if move else 'Copied'} {sub_class} -> {super_class}\")\n",
    "    print(\"Dataset reorganization complete!\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eae50ae5-2a62-4c48-9d28-529d72a93adb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reorganize_imagenet_dataset(mapping_file='../data/class_subset_240.json', \n",
    "#                    src_root='../data/Imagenet-Visual Stimuli', \n",
    "#                    dst_root='../data/Imagenet-240', \n",
    "#                    move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d0099f0-1146-4bdf-a4e8-3f24d36d275f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abacus',\n",
       " 'abaya',\n",
       " 'academic_gown',\n",
       " 'accordion',\n",
       " 'acorn',\n",
       " 'acorn_squash',\n",
       " 'acoustic_guitar',\n",
       " 'admiral',\n",
       " 'affenpinscher',\n",
       " 'afghan_hound',\n",
       " 'african_chameleon',\n",
       " 'african_crocodile',\n",
       " 'african_elephant',\n",
       " 'african_grey',\n",
       " 'african_hunting_dog',\n",
       " 'agama',\n",
       " 'agaric',\n",
       " 'aircraft_carrier',\n",
       " 'airedale',\n",
       " 'airliner',\n",
       " 'airship',\n",
       " 'albatross',\n",
       " 'alligator_lizard',\n",
       " 'alp',\n",
       " 'altar',\n",
       " 'ambulance',\n",
       " 'american_alligator',\n",
       " 'american_black_bear',\n",
       " 'american_chameleon',\n",
       " 'american_coot',\n",
       " 'american_egret',\n",
       " 'american_lobster',\n",
       " 'american_staffordshire_terrier',\n",
       " 'amphibian',\n",
       " 'analog_clock',\n",
       " 'anemone_fish',\n",
       " 'angora',\n",
       " 'ant',\n",
       " 'apiary',\n",
       " 'appenzeller',\n",
       " 'apron',\n",
       " 'arabian_camel',\n",
       " 'arctic_fox',\n",
       " 'armadillo',\n",
       " 'artichoke',\n",
       " 'ashcan',\n",
       " 'assault_rifle',\n",
       " 'australian_terrier',\n",
       " 'axolotl',\n",
       " 'baboon',\n",
       " 'backpack',\n",
       " 'badger',\n",
       " 'bagel',\n",
       " 'bakery',\n",
       " 'balance_beam',\n",
       " 'bald_eagle',\n",
       " 'balloon',\n",
       " 'ballplayer',\n",
       " 'ballpoint',\n",
       " 'banana',\n",
       " 'banded_gecko',\n",
       " 'band_aid',\n",
       " 'banjo',\n",
       " 'bannister',\n",
       " 'barbell',\n",
       " 'barbershop',\n",
       " 'barber_chair',\n",
       " 'barn',\n",
       " 'barn_spider',\n",
       " 'barometer',\n",
       " 'barracouta',\n",
       " 'barrel',\n",
       " 'barrow',\n",
       " 'baseball',\n",
       " 'basenji',\n",
       " 'basketball',\n",
       " 'basset',\n",
       " 'bassinet',\n",
       " 'bassoon',\n",
       " 'bathing_cap',\n",
       " 'bathtub',\n",
       " 'bath_towel',\n",
       " 'beach_wagon',\n",
       " 'beacon',\n",
       " 'beagle',\n",
       " 'beaker',\n",
       " 'bearskin',\n",
       " 'beaver',\n",
       " 'bedlington_terrier',\n",
       " 'bee',\n",
       " 'beer_bottle',\n",
       " 'beer_glass',\n",
       " 'bee_eater',\n",
       " 'bell_cote',\n",
       " 'bell_pepper',\n",
       " 'bernese_mountain_dog',\n",
       " 'bib',\n",
       " 'bicycle_built_for_two',\n",
       " 'bighorn',\n",
       " 'bikini',\n",
       " 'binder',\n",
       " 'binoculars',\n",
       " 'birdhouse',\n",
       " 'bison',\n",
       " 'bittern',\n",
       " 'black_and_gold_garden_spider',\n",
       " 'black_and_tan_coonhound',\n",
       " 'black_footed_ferret',\n",
       " 'black_grouse',\n",
       " 'black_stork',\n",
       " 'black_swan',\n",
       " 'black_widow',\n",
       " 'blenheim_spaniel',\n",
       " 'bloodhound',\n",
       " 'bluetick',\n",
       " 'boathouse',\n",
       " 'boa_constrictor',\n",
       " 'bobsled',\n",
       " 'bolete',\n",
       " 'bolo_tie',\n",
       " 'bonnet',\n",
       " 'bookcase',\n",
       " 'bookshop',\n",
       " 'book_jacket',\n",
       " 'border_collie',\n",
       " 'border_terrier',\n",
       " 'borzoi',\n",
       " 'boston_bull',\n",
       " 'bottlecap',\n",
       " 'bouvier_des_flandres',\n",
       " 'bow',\n",
       " 'bow_tie',\n",
       " 'boxer',\n",
       " 'box_turtle',\n",
       " 'brabancon_griffon',\n",
       " 'brain_coral',\n",
       " 'brambling',\n",
       " 'brass',\n",
       " 'brassiere',\n",
       " 'breakwater',\n",
       " 'breastplate',\n",
       " 'briard',\n",
       " 'brittany_spaniel',\n",
       " 'broccoli',\n",
       " 'broom',\n",
       " 'brown_bear',\n",
       " 'bubble',\n",
       " 'bucket',\n",
       " 'buckeye',\n",
       " 'buckle',\n",
       " 'bulbul',\n",
       " 'bulletproof_vest',\n",
       " 'bullet_train',\n",
       " 'bullfrog',\n",
       " 'bull_mastiff',\n",
       " 'burrito',\n",
       " 'bustard',\n",
       " 'butcher_shop',\n",
       " 'butternut_squash',\n",
       " 'cab',\n",
       " 'cabbage_butterfly',\n",
       " 'cairn',\n",
       " 'caldron',\n",
       " 'candle',\n",
       " 'cannon',\n",
       " 'canoe',\n",
       " 'can_opener',\n",
       " 'capuchin',\n",
       " 'carbonara',\n",
       " 'cardigan',\n",
       " 'cardigan_welsh_corgi',\n",
       " 'cardoon',\n",
       " 'carousel',\n",
       " 'carpenter_s_kit',\n",
       " 'carton',\n",
       " 'car_mirror',\n",
       " 'car_wheel',\n",
       " 'cash_machine',\n",
       " 'cassette',\n",
       " 'cassette_player',\n",
       " 'castle',\n",
       " 'catamaran',\n",
       " 'cauliflower',\n",
       " 'cd_player',\n",
       " 'cello',\n",
       " 'cellular_telephone',\n",
       " 'centipede',\n",
       " 'chain',\n",
       " 'chainlink_fence',\n",
       " 'chain_mail',\n",
       " 'chain_saw',\n",
       " 'chambered_nautilus',\n",
       " 'cheeseburger',\n",
       " 'cheetah',\n",
       " 'chesapeake_bay_retriever',\n",
       " 'chest',\n",
       " 'chickadee',\n",
       " 'chiffonier',\n",
       " 'chihuahua',\n",
       " 'chime',\n",
       " 'chimpanzee',\n",
       " 'china_cabinet',\n",
       " 'chiton',\n",
       " 'chocolate_sauce',\n",
       " 'chow',\n",
       " 'christmas_stocking',\n",
       " 'church',\n",
       " 'cicada',\n",
       " 'cinema',\n",
       " 'cleaver',\n",
       " 'cliff',\n",
       " 'cliff_dwelling',\n",
       " 'cloak',\n",
       " 'clog',\n",
       " 'clumber',\n",
       " 'cock',\n",
       " 'cocker_spaniel',\n",
       " 'cockroach',\n",
       " 'cocktail_shaker',\n",
       " 'coffeepot',\n",
       " 'coffee_mug',\n",
       " 'coho',\n",
       " 'coil',\n",
       " 'collie',\n",
       " 'colobus',\n",
       " 'combination_lock',\n",
       " 'comic_book',\n",
       " 'common_iguana',\n",
       " 'common_newt',\n",
       " 'computer_keyboard',\n",
       " 'conch',\n",
       " 'confectionery',\n",
       " 'consomme',\n",
       " 'container_ship',\n",
       " 'convertible',\n",
       " 'coral_fungus',\n",
       " 'coral_reef',\n",
       " 'corkscrew',\n",
       " 'corn',\n",
       " 'cornet',\n",
       " 'coucal',\n",
       " 'cougar',\n",
       " 'cowboy_boot',\n",
       " 'cowboy_hat',\n",
       " 'coyote',\n",
       " 'cradle',\n",
       " 'crane',\n",
       " 'crane_bird',\n",
       " 'crash_helmet',\n",
       " 'crate',\n",
       " 'crayfish',\n",
       " 'crib',\n",
       " 'cricket',\n",
       " 'crock_pot',\n",
       " 'croquet_ball',\n",
       " 'crossword_puzzle',\n",
       " 'crutch',\n",
       " 'cucumber',\n",
       " 'cuirass',\n",
       " 'cup',\n",
       " 'curly_coated_retriever',\n",
       " 'custard_apple',\n",
       " 'daisy',\n",
       " 'dalmatian',\n",
       " 'dam',\n",
       " 'damselfly',\n",
       " 'dandie_dinmont',\n",
       " 'desk',\n",
       " 'desktop_computer',\n",
       " 'dhole',\n",
       " 'dial_telephone',\n",
       " 'diamondback',\n",
       " 'diaper',\n",
       " 'digital_clock',\n",
       " 'digital_watch',\n",
       " 'dingo',\n",
       " 'dining_table',\n",
       " 'dishrag',\n",
       " 'dishwasher',\n",
       " 'disk_brake',\n",
       " 'doberman',\n",
       " 'dock',\n",
       " 'dogsled',\n",
       " 'dome',\n",
       " 'doormat',\n",
       " 'dough',\n",
       " 'dowitcher',\n",
       " 'dragonfly',\n",
       " 'drake',\n",
       " 'drilling_platform',\n",
       " 'drum',\n",
       " 'drumstick',\n",
       " 'dugong',\n",
       " 'dumbbell',\n",
       " 'dungeness_crab',\n",
       " 'dung_beetle',\n",
       " 'dutch_oven',\n",
       " 'ear',\n",
       " 'earthstar',\n",
       " 'echidna',\n",
       " 'eel',\n",
       " 'eft',\n",
       " 'eggnog',\n",
       " 'egyptian_cat',\n",
       " 'electric_fan',\n",
       " 'electric_guitar',\n",
       " 'electric_locomotive',\n",
       " 'electric_ray',\n",
       " 'english_foxhound',\n",
       " 'english_setter',\n",
       " 'english_springer',\n",
       " 'entertainment_center',\n",
       " 'entlebucher',\n",
       " 'envelope',\n",
       " 'eskimo_dog',\n",
       " 'espresso',\n",
       " 'espresso_maker',\n",
       " 'european_fire_salamander',\n",
       " 'european_gallinule',\n",
       " 'face_powder',\n",
       " 'feather_boa',\n",
       " 'fiddler_crab',\n",
       " 'fig',\n",
       " 'file',\n",
       " 'fireboat',\n",
       " 'fire_engine',\n",
       " 'fire_screen',\n",
       " 'flagpole',\n",
       " 'flamingo',\n",
       " 'flatworm',\n",
       " 'flat_coated_retriever',\n",
       " 'flute',\n",
       " 'fly',\n",
       " 'folding_chair',\n",
       " 'football_helmet',\n",
       " 'forklift',\n",
       " 'fountain',\n",
       " 'fountain_pen',\n",
       " 'four_poster',\n",
       " 'fox_squirrel',\n",
       " 'freight_car',\n",
       " 'french_bulldog',\n",
       " 'french_horn',\n",
       " 'french_loaf',\n",
       " 'frilled_lizard',\n",
       " 'frying_pan',\n",
       " 'fur_coat',\n",
       " 'gar',\n",
       " 'garbage_truck',\n",
       " 'garden_spider',\n",
       " 'garter_snake',\n",
       " 'gasmask',\n",
       " 'gas_pump',\n",
       " 'gazelle',\n",
       " 'german_shepherd',\n",
       " 'german_short_haired_pointer',\n",
       " 'geyser',\n",
       " 'giant_panda',\n",
       " 'giant_schnauzer',\n",
       " 'gibbon',\n",
       " 'gila_monster',\n",
       " 'goblet',\n",
       " 'golden_retriever',\n",
       " 'goldfinch',\n",
       " 'goldfish',\n",
       " 'golfcart',\n",
       " 'golf_ball',\n",
       " 'gondola',\n",
       " 'gong',\n",
       " 'goose',\n",
       " 'gordon_setter',\n",
       " 'gorilla',\n",
       " 'gown',\n",
       " 'go_kart',\n",
       " 'grand_piano',\n",
       " 'granny_smith',\n",
       " 'grasshopper',\n",
       " 'greater_swiss_mountain_dog',\n",
       " 'great_dane',\n",
       " 'great_grey_owl',\n",
       " 'great_pyrenees',\n",
       " 'great_white_shark',\n",
       " 'greenhouse',\n",
       " 'green_lizard',\n",
       " 'green_mamba',\n",
       " 'green_snake',\n",
       " 'grey_fox',\n",
       " 'grey_whale',\n",
       " 'grille',\n",
       " 'grocery_store',\n",
       " 'groenendael',\n",
       " 'groom',\n",
       " 'ground_beetle',\n",
       " 'guacamole',\n",
       " 'guenon',\n",
       " 'guillotine',\n",
       " 'guinea_pig',\n",
       " 'gyromitra',\n",
       " 'hair_slide',\n",
       " 'hair_spray',\n",
       " 'half_track',\n",
       " 'hammer',\n",
       " 'hammerhead',\n",
       " 'hamper',\n",
       " 'hamster',\n",
       " 'handkerchief',\n",
       " 'hand_blower',\n",
       " 'hand_held_computer',\n",
       " 'hard_disc',\n",
       " 'hare',\n",
       " 'harmonica',\n",
       " 'harp',\n",
       " 'hartebeest',\n",
       " 'harvester',\n",
       " 'harvestman',\n",
       " 'hatchet',\n",
       " 'hay',\n",
       " 'head_cabbage',\n",
       " 'hen',\n",
       " 'hen_of_the_woods',\n",
       " 'hermit_crab',\n",
       " 'hip',\n",
       " 'hippopotamus',\n",
       " 'hog',\n",
       " 'hognose_snake',\n",
       " 'holster',\n",
       " 'home_theater',\n",
       " 'honeycomb',\n",
       " 'hook',\n",
       " 'hoopskirt',\n",
       " 'horizontal_bar',\n",
       " 'hornbill',\n",
       " 'horned_viper',\n",
       " 'horse_cart',\n",
       " 'hotdog',\n",
       " 'hot_pot',\n",
       " 'hourglass',\n",
       " 'house_finch',\n",
       " 'howler_monkey',\n",
       " 'hummingbird',\n",
       " 'hyena',\n",
       " 'ibex',\n",
       " 'ibizan_hound',\n",
       " 'ice_bear',\n",
       " 'ice_cream',\n",
       " 'ice_lolly',\n",
       " 'impala',\n",
       " 'indian_cobra',\n",
       " 'indian_elephant',\n",
       " 'indigo_bunting',\n",
       " 'indri',\n",
       " 'ipod',\n",
       " 'irish_setter',\n",
       " 'irish_terrier',\n",
       " 'irish_water_spaniel',\n",
       " 'irish_wolfhound',\n",
       " 'iron',\n",
       " 'isopod',\n",
       " 'italian_greyhound',\n",
       " 'jacamar',\n",
       " 'jackfruit',\n",
       " 'jack_o_lantern',\n",
       " 'jaguar',\n",
       " 'japanese_spaniel',\n",
       " 'jay',\n",
       " 'jean',\n",
       " 'jeep',\n",
       " 'jellyfish',\n",
       " 'jersey',\n",
       " 'jigsaw_puzzle',\n",
       " 'jinrikisha',\n",
       " 'joystick',\n",
       " 'junco',\n",
       " 'keeshond',\n",
       " 'kelpie',\n",
       " 'kerry_blue_terrier',\n",
       " 'killer_whale',\n",
       " 'kimono',\n",
       " 'king_crab',\n",
       " 'king_penguin',\n",
       " 'king_snake',\n",
       " 'kite',\n",
       " 'kit_fox',\n",
       " 'knee_pad',\n",
       " 'knot',\n",
       " 'koala',\n",
       " 'komodo_dragon',\n",
       " 'komondor',\n",
       " 'kuvasz',\n",
       " 'labrador_retriever',\n",
       " 'lab_coat',\n",
       " 'lacewing',\n",
       " 'ladle',\n",
       " 'ladybug',\n",
       " 'lakeland_terrier',\n",
       " 'lakeside',\n",
       " 'lampshade',\n",
       " 'langur',\n",
       " 'laptop',\n",
       " 'lawn_mower',\n",
       " 'leafhopper',\n",
       " 'leaf_beetle',\n",
       " 'leatherback_turtle',\n",
       " 'lemon',\n",
       " 'lens_cap',\n",
       " 'leonberg',\n",
       " 'leopard',\n",
       " 'lesser_panda',\n",
       " 'letter_opener',\n",
       " 'lhasa',\n",
       " 'library',\n",
       " 'lifeboat',\n",
       " 'lighter',\n",
       " 'limousine',\n",
       " 'limpkin',\n",
       " 'liner',\n",
       " 'lion',\n",
       " 'lionfish',\n",
       " 'lipstick',\n",
       " 'little_blue_heron',\n",
       " 'llama',\n",
       " 'loafer',\n",
       " 'loggerhead',\n",
       " 'long_horned_beetle',\n",
       " 'lorikeet',\n",
       " 'lotion',\n",
       " 'loudspeaker',\n",
       " 'loupe',\n",
       " 'lumbermill',\n",
       " 'lycaenid',\n",
       " 'lynx',\n",
       " 'macaque',\n",
       " 'macaw',\n",
       " 'madagascar_cat',\n",
       " 'magnetic_compass',\n",
       " 'magpie',\n",
       " 'mailbag',\n",
       " 'mailbox',\n",
       " 'maillot',\n",
       " 'malamute',\n",
       " 'malinois',\n",
       " 'maltese_dog',\n",
       " 'manhole_cover',\n",
       " 'mantis',\n",
       " 'maraca',\n",
       " 'marimba',\n",
       " 'marmoset',\n",
       " 'marmot',\n",
       " 'mashed_potato',\n",
       " 'mask',\n",
       " 'matchstick',\n",
       " 'maypole',\n",
       " 'maze',\n",
       " 'measuring_cup',\n",
       " 'meat_loaf',\n",
       " 'medicine_chest',\n",
       " 'meerkat',\n",
       " 'megalith',\n",
       " 'menu',\n",
       " 'mexican_hairless',\n",
       " 'microphone',\n",
       " 'microwave',\n",
       " 'military_uniform',\n",
       " 'milk_can',\n",
       " 'miniature_pinscher',\n",
       " 'miniature_poodle',\n",
       " 'miniature_schnauzer',\n",
       " 'minibus',\n",
       " 'miniskirt',\n",
       " 'minivan',\n",
       " 'mink',\n",
       " 'missile',\n",
       " 'mitten',\n",
       " 'mixing_bowl',\n",
       " 'mobile_home',\n",
       " 'model_t',\n",
       " 'modem',\n",
       " 'monarch',\n",
       " 'monastery',\n",
       " 'mongoose',\n",
       " 'monitor',\n",
       " 'moped',\n",
       " 'mortar',\n",
       " 'mortarboard',\n",
       " 'mosque',\n",
       " 'mosquito_net',\n",
       " 'motor_scooter',\n",
       " 'mountain_bike',\n",
       " 'mountain_tent',\n",
       " 'mouse',\n",
       " 'mousetrap',\n",
       " 'moving_van',\n",
       " 'mud_turtle',\n",
       " 'mushroom',\n",
       " 'muzzle',\n",
       " 'nail',\n",
       " 'necklace',\n",
       " 'neck_brace',\n",
       " 'nematode',\n",
       " 'newfoundland',\n",
       " 'night_snake',\n",
       " 'nipple',\n",
       " 'norfolk_terrier',\n",
       " 'norwegian_elkhound',\n",
       " 'norwich_terrier',\n",
       " 'notebook',\n",
       " 'obelisk',\n",
       " 'oboe',\n",
       " 'ocarina',\n",
       " 'odometer',\n",
       " 'oil_filter',\n",
       " 'old_english_sheepdog',\n",
       " 'orange',\n",
       " 'orangutan',\n",
       " 'organ',\n",
       " 'oscilloscope',\n",
       " 'ostrich',\n",
       " 'otter',\n",
       " 'otterhound',\n",
       " 'overskirt',\n",
       " 'ox',\n",
       " 'oxcart',\n",
       " 'oxygen_mask',\n",
       " 'oystercatcher',\n",
       " 'packet',\n",
       " 'paddle',\n",
       " 'paddlewheel',\n",
       " 'padlock',\n",
       " 'paintbrush',\n",
       " 'pajama',\n",
       " 'palace',\n",
       " 'panpipe',\n",
       " 'paper_towel',\n",
       " 'papillon',\n",
       " 'parachute',\n",
       " 'parallel_bars',\n",
       " 'parking_meter',\n",
       " 'park_bench',\n",
       " 'partridge',\n",
       " 'passenger_car',\n",
       " 'patas',\n",
       " 'patio',\n",
       " 'pay_phone',\n",
       " 'peacock',\n",
       " 'pedestal',\n",
       " 'pekinese',\n",
       " 'pelican',\n",
       " 'pembroke',\n",
       " 'pencil_box',\n",
       " 'pencil_sharpener',\n",
       " 'perfume',\n",
       " 'persian_cat',\n",
       " 'petri_dish',\n",
       " 'photocopier',\n",
       " 'pick',\n",
       " 'pickelhaube',\n",
       " 'picket_fence',\n",
       " 'pickup',\n",
       " 'pier',\n",
       " 'piggy_bank',\n",
       " 'pillow',\n",
       " 'pill_bottle',\n",
       " 'pineapple',\n",
       " 'ping_pong_ball',\n",
       " 'pinwheel',\n",
       " 'pirate',\n",
       " 'pitcher',\n",
       " 'pizza',\n",
       " 'plane',\n",
       " 'planetarium',\n",
       " 'plastic_bag',\n",
       " 'plate',\n",
       " 'plate_rack',\n",
       " 'platypus',\n",
       " 'plow',\n",
       " 'plunger',\n",
       " 'polaroid_camera',\n",
       " 'pole',\n",
       " 'polecat',\n",
       " 'police_van',\n",
       " 'pomegranate',\n",
       " 'pomeranian',\n",
       " 'poncho',\n",
       " 'pool_table',\n",
       " 'pop_bottle',\n",
       " 'porcupine',\n",
       " 'pot',\n",
       " 'potpie',\n",
       " 'potter_s_wheel',\n",
       " 'power_drill',\n",
       " 'prairie_chicken',\n",
       " 'prayer_rug',\n",
       " 'pretzel',\n",
       " 'printer',\n",
       " 'prison',\n",
       " 'proboscis_monkey',\n",
       " 'projectile',\n",
       " 'projector',\n",
       " 'promontory',\n",
       " 'ptarmigan',\n",
       " 'puck',\n",
       " 'puffer',\n",
       " 'pug',\n",
       " 'punching_bag',\n",
       " 'purse',\n",
       " 'quail',\n",
       " 'quill',\n",
       " 'quilt',\n",
       " 'racer',\n",
       " 'racket',\n",
       " 'radiator',\n",
       " 'radio',\n",
       " 'radio_telescope',\n",
       " 'rain_barrel',\n",
       " 'ram',\n",
       " 'rapeseed',\n",
       " 'recreational_vehicle',\n",
       " 'redbone',\n",
       " 'redshank',\n",
       " 'red_backed_sandpiper',\n",
       " 'red_breasted_merganser',\n",
       " 'red_fox',\n",
       " 'red_wine',\n",
       " 'red_wolf',\n",
       " 'reel',\n",
       " 'reflex_camera',\n",
       " 'refrigerator',\n",
       " 'remote_control',\n",
       " 'restaurant',\n",
       " 'revolver',\n",
       " 'rhinoceros_beetle',\n",
       " 'rhodesian_ridgeback',\n",
       " 'rifle',\n",
       " 'ringlet',\n",
       " 'ringneck_snake',\n",
       " 'robin',\n",
       " 'rocking_chair',\n",
       " 'rock_beauty',\n",
       " 'rock_crab',\n",
       " 'rock_python',\n",
       " 'rotisserie',\n",
       " 'rottweiler',\n",
       " 'rubber_eraser',\n",
       " 'ruddy_turnstone',\n",
       " 'ruffed_grouse',\n",
       " 'rugby_ball',\n",
       " 'rule',\n",
       " 'running_shoe',\n",
       " 'safe',\n",
       " 'safety_pin',\n",
       " 'saint_bernard',\n",
       " 'saltshaker',\n",
       " 'saluki',\n",
       " 'samoyed',\n",
       " 'sandal',\n",
       " 'sandbar',\n",
       " 'sarong',\n",
       " 'sax',\n",
       " 'scabbard',\n",
       " 'scale',\n",
       " 'schipperke',\n",
       " 'school_bus',\n",
       " 'schooner',\n",
       " 'scoreboard',\n",
       " 'scorpion',\n",
       " 'scotch_terrier',\n",
       " 'scottish_deerhound',\n",
       " 'screen',\n",
       " 'screw',\n",
       " 'screwdriver',\n",
       " 'scuba_diver',\n",
       " 'sealyham_terrier',\n",
       " 'seashore',\n",
       " 'seat_belt',\n",
       " 'sea_anemone',\n",
       " 'sea_cucumber',\n",
       " 'sea_lion',\n",
       " 'sea_slug',\n",
       " 'sea_snake',\n",
       " 'sea_urchin',\n",
       " 'sewing_machine',\n",
       " 'shetland_sheepdog',\n",
       " 'shield',\n",
       " 'shih_tzu',\n",
       " 'shoe_shop',\n",
       " 'shoji',\n",
       " 'shopping_basket',\n",
       " 'shopping_cart',\n",
       " 'shovel',\n",
       " 'shower_cap',\n",
       " 'shower_curtain',\n",
       " 'siamang',\n",
       " 'siamese_cat',\n",
       " 'siberian_husky',\n",
       " 'sidewinder',\n",
       " 'silky_terrier',\n",
       " 'ski',\n",
       " 'ski_mask',\n",
       " 'skunk',\n",
       " 'sleeping_bag',\n",
       " 'slide_rule',\n",
       " 'sliding_door',\n",
       " 'slot',\n",
       " 'sloth_bear',\n",
       " 'slug',\n",
       " 'snail',\n",
       " 'snorkel',\n",
       " 'snowmobile',\n",
       " 'snowplow',\n",
       " 'snow_leopard',\n",
       " 'soap_dispenser',\n",
       " 'soccer_ball',\n",
       " 'sock',\n",
       " 'soft_coated_wheaten_terrier',\n",
       " 'solar_dish',\n",
       " 'sombrero',\n",
       " 'sorrel',\n",
       " 'soup_bowl',\n",
       " 'space_bar',\n",
       " 'space_heater',\n",
       " 'space_shuttle',\n",
       " 'spaghetti_squash',\n",
       " 'spatula',\n",
       " 'speedboat',\n",
       " 'spider_monkey',\n",
       " 'spider_web',\n",
       " 'spindle',\n",
       " 'spiny_lobster',\n",
       " 'spoonbill',\n",
       " 'sports_car',\n",
       " 'spotlight',\n",
       " 'spotted_salamander',\n",
       " 'squirrel_monkey',\n",
       " 'staffordshire_bullterrier',\n",
       " 'stage',\n",
       " 'standard_poodle',\n",
       " 'standard_schnauzer',\n",
       " 'starfish',\n",
       " 'steam_locomotive',\n",
       " 'steel_arch_bridge',\n",
       " 'steel_drum',\n",
       " 'stethoscope',\n",
       " 'stingray',\n",
       " 'stinkhorn',\n",
       " 'stole',\n",
       " 'stone_wall',\n",
       " 'stopwatch',\n",
       " 'stove',\n",
       " 'strainer',\n",
       " 'strawberry',\n",
       " 'streetcar',\n",
       " 'street_sign',\n",
       " 'stretcher',\n",
       " 'studio_couch',\n",
       " 'stupa',\n",
       " 'sturgeon',\n",
       " 'submarine',\n",
       " 'suit',\n",
       " 'sulphur_butterfly',\n",
       " 'sulphur_crested_cockatoo',\n",
       " 'sundial',\n",
       " 'sunglass',\n",
       " 'sunglasses',\n",
       " 'sunscreen',\n",
       " 'suspension_bridge',\n",
       " 'sussex_spaniel',\n",
       " 'swab',\n",
       " 'sweatshirt',\n",
       " 'swimming_trunks',\n",
       " 'swing',\n",
       " 'switch',\n",
       " 'syringe',\n",
       " 'tabby',\n",
       " 'table_lamp',\n",
       " 'tailed_frog',\n",
       " 'tank',\n",
       " 'tank_suit',\n",
       " 'tape_player',\n",
       " 'tarantula',\n",
       " 'teapot',\n",
       " 'teddy',\n",
       " 'television',\n",
       " 'tench',\n",
       " 'tennis_ball',\n",
       " 'terrapin',\n",
       " 'thatch',\n",
       " 'theater_curtain',\n",
       " 'thimble',\n",
       " 'three_toed_sloth',\n",
       " 'thresher',\n",
       " 'throne',\n",
       " 'thunder_snake',\n",
       " 'tibetan_mastiff',\n",
       " 'tibetan_terrier',\n",
       " 'tick',\n",
       " 'tiger',\n",
       " 'tiger_beetle',\n",
       " 'tiger_cat',\n",
       " 'tiger_shark',\n",
       " 'tile_roof',\n",
       " 'timber_wolf',\n",
       " 'titi',\n",
       " 'toaster',\n",
       " 'tobacco_shop',\n",
       " 'toilet_seat',\n",
       " 'toilet_tissue',\n",
       " 'torch',\n",
       " 'totem_pole',\n",
       " 'toucan',\n",
       " 'tow_truck',\n",
       " 'toyshop',\n",
       " 'toy_poodle',\n",
       " 'toy_terrier',\n",
       " 'tractor',\n",
       " 'traffic_light',\n",
       " 'trailer_truck',\n",
       " 'tray',\n",
       " 'tree_frog',\n",
       " 'trench_coat',\n",
       " 'triceratops',\n",
       " 'tricycle',\n",
       " 'trifle',\n",
       " 'trilobite',\n",
       " 'trimaran',\n",
       " 'tripod',\n",
       " 'triumphal_arch',\n",
       " 'trolleybus',\n",
       " 'trombone',\n",
       " 'tub',\n",
       " 'turnstile',\n",
       " 'tusker',\n",
       " 'typewriter_keyboard',\n",
       " 'umbrella',\n",
       " 'unicycle',\n",
       " 'upright',\n",
       " 'vacuum',\n",
       " 'valley',\n",
       " 'vase',\n",
       " 'vault',\n",
       " 'velvet',\n",
       " 'vending_machine',\n",
       " 'vestment',\n",
       " 'viaduct',\n",
       " 'vine_snake',\n",
       " 'violin',\n",
       " 'vizsla',\n",
       " 'volcano',\n",
       " 'volleyball',\n",
       " 'vulture',\n",
       " 'waffle_iron',\n",
       " 'walker_hound',\n",
       " 'walking_stick',\n",
       " 'wallaby',\n",
       " 'wallet',\n",
       " 'wall_clock',\n",
       " 'wardrobe',\n",
       " 'warplane',\n",
       " 'warthog',\n",
       " 'washbasin',\n",
       " 'washer',\n",
       " 'water_bottle',\n",
       " 'water_buffalo',\n",
       " 'water_jug',\n",
       " 'water_ouzel',\n",
       " 'water_snake',\n",
       " 'water_tower',\n",
       " 'weasel',\n",
       " 'web_site',\n",
       " 'weevil',\n",
       " 'weimaraner',\n",
       " 'welsh_springer_spaniel',\n",
       " 'west_highland_white_terrier',\n",
       " 'whippet',\n",
       " 'whiptail',\n",
       " 'whiskey_jug',\n",
       " 'whistle',\n",
       " 'white_stork',\n",
       " 'white_wolf',\n",
       " 'wig',\n",
       " 'wild_boar',\n",
       " 'window_screen',\n",
       " 'window_shade',\n",
       " 'windsor_tie',\n",
       " 'wine_bottle',\n",
       " 'wing',\n",
       " 'wire_haired_fox_terrier',\n",
       " 'wok',\n",
       " 'wolf_spider',\n",
       " 'wombat',\n",
       " 'wooden_spoon',\n",
       " 'wood_rabbit',\n",
       " 'wool',\n",
       " 'worm_fence',\n",
       " 'wreck',\n",
       " 'yawl',\n",
       " 'yellow_lady_s_slipper',\n",
       " 'yorkshire_terrier',\n",
       " 'yurt',\n",
       " 'zebra',\n",
       " 'zucchini']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../data/Imagenet-Visual Stimuli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a4f18-0cbf-451e-be8c-1aa156eff8a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset Processing for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f7ba77-0e7b-46c4-9823-85ed74ec2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "027fe9b8-8ee9-4f76-b0b0-20f528f20261",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, root_dir, samples, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.samples)          \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.samples[idx]\n",
    "\n",
    "        df = pd.read_csv(file_path, header=None, index_col=0)\n",
    "        eeg_data = torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "        if eeg_data.shape[0] < eeg_data.shape[1]:\n",
    "            eeg_data = eeg_data.T\n",
    "\n",
    "        if self.transform:\n",
    "            eeg_data = self.transform(eeg_data)\n",
    "\n",
    "        return eeg_data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd4342db-dfec-4a91-bd75-848017a33149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(root_dir, val_ratio=0.25, random_state=42): \n",
    "    class_names = os.listdir(root_dir)\n",
    "    class_to_idx = {cls:idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "    all_samples = []\n",
    "    all_labels = []\n",
    "\n",
    "    for cls in class_names:\n",
    "        cls_dir = os.path.join(root_dir, cls)\n",
    "        \n",
    "        for fname in os.listdir(cls_dir): \n",
    "            if fname.endswith('.csv'):\n",
    "                path = os.path.join(cls_dir, fname)\n",
    "                all_samples.append((path, class_to_idx[cls]))\n",
    "                all_labels.append(class_to_idx[cls])\n",
    "\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        list(range(len(all_samples))), \n",
    "        test_size=val_ratio, \n",
    "        random_state=random_state, \n",
    "        stratify=all_labels\n",
    "    )\n",
    "\n",
    "    train_samples = [all_samples[i] for i in train_idx]\n",
    "    val_samples = [all_samples[i] for i in val_idx]\n",
    "\n",
    "    train_dataset = EEGDataset(root_dir, train_samples)\n",
    "    val_dataset = EEGDataset(root_dir, val_samples)\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0696ba6-64c0-427e-895e-0dead7a43cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "\n",
    "    lengths = torch.tensor([seq.size(0) for seq in sequences], dtype=torch.long)\n",
    "    padded_seqs = pad_sequence(sequences, batch_first=True)\n",
    "\n",
    "    return padded_seqs, torch.tensor(labels), lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44d72aba-d8c1-46e8-a055-52cf6ba2cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(dataset):\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    cls_samples_count = defaultdict(int)\n",
    "    \n",
    "    for sample in dataset.samples:\n",
    "        cls_idx = sample[1]\n",
    "        cls_samples_count[cls_idx] += 1\n",
    "    \n",
    "    for cls_idx, count in cls_samples_count.items(): \n",
    "        cls_samples_count[cls_idx] = round(count/len(dataset.samples), 4)\n",
    "\n",
    "    return cls_samples_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc8180c7-8721-41be-9a88-1dfd1e25a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../data/Classes_Regrouped_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3aa364a-238c-4491-b180-38f91b9e998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = make_datasets(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56ae671d-61a8-4965-a5c7-ab50304d1aef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_cls_wts_dict = get_class_weights(train_dataset)\n",
    "\n",
    "train_cls_wts = [item[1] for item in sorted(train_cls_wts_dict.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa31a208-6ab1-4ac6-925c-669529875a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 118)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_cls_wts_dict), len(os.listdir(root_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de184be0-616d-4513-8df8-33ee2a2fdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=train_cls_wts, \n",
    "                                num_samples=len(train_dataset.samples), \n",
    "                                replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9db34b-54f7-4a6d-8e85-0a7f7d0ba655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, sampler=sampler, \n",
    "                          collate_fn=collate_fn, num_workers=4, pin_memory=False, \n",
    "                          persistent_workers=True, prefetch_factor=2)\n",
    "        \n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn, \n",
    "                        num_workers=4, pin_memory=False, persistent_workers=True, prefetch_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5412098-f7ad-4b4f-8e31-73655285f7d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # class_weights\n",
    "# samples_count = 0\n",
    "# dataset_dir = '../data/Class_Combined_Balanced_Dataset'\n",
    "# class_wts = defaultdict(float)\n",
    "\n",
    "# for cls in os.listdir(dataset_dir): \n",
    "#     print(cls)\n",
    "#     cls_count = len(os.listdir(os.path.join(dataset_dir, cls)))\n",
    "#     samples_count += cls_count\n",
    "#     class_wts[cls] = cls_count\n",
    "    \n",
    "# print(f\"Total Samples: {samples_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128be87e-ba11-4475-a173-b38957af8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/class_samples_count.json', 'w') as f:\n",
    "#     json.dump(class_wts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fbc990-5aeb-4894-a035-e2210b0f6ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cls, count in class_wts.items():\n",
    "#     class_wts[cls] = count/samples_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb4ed5-1c53-46bc-906e-cb1e4614eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/class_weights.json', 'w') as f:\n",
    "#     json.dump(class_wts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a21f8-2bf8-43e3-a97e-921a0309a3ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2419cd3-599a-433b-a84e-8a69bf5f8f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e6a7229-ac9e-4bed-bd54-97f1e0cbc70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EegLstm(nn.Module):\n",
    "    def __init__(self, input_dims=5, hidden_dims=128, num_layers=3, dropout=0.3 , num_classes=len(os.listdir(root_dir))):\n",
    "        super(EegLstm, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dims,\n",
    "            hidden_size=hidden_dims,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers >= 2 else 0, \n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dims*2, hidden_dims),\n",
    "            nn.BatchNorm1d(hidden_dims),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dims, hidden_dims),\n",
    "            nn.BatchNorm1d(hidden_dims),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dims, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lengths=None):\n",
    "        if lengths is not None:\n",
    "            packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                x, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "\n",
    "            packed_out, (h_n, c_n) = self.lstm(packed)\n",
    "\n",
    "        else:\n",
    "            out, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        last_hidden_backward, last_hidden_forward = h_n[-1], h_n[-2]\n",
    "        logits=self.fc(torch.cat((last_hidden_backward, last_hidden_forward), dim=1))\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "515f59a8-507f-47c7-8e8d-a76200753e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module): \n",
    "    def __init__(self, noise_dim=100, eeg_feature_dim=256, channels=3): \n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        input_dim = noise_dim + eeg_feature_dim \n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512*4*4), \n",
    "            nn.ReLU(True), \n",
    "            nn.Unflatten(1, (512,4,4)), \n",
    "            \n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bi8as=False), \n",
    "            nn.BatchNorm2d(256), \n",
    "            nn.ReLU(True), \n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False), \n",
    "            nn.BatchNorm2d(128), \n",
    "            nn.ReLU(True), \n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False), \n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(True), \n",
    "\n",
    "            nn.ConvTranspose2d(64, channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()            \n",
    "        )\n",
    "\n",
    "    def forward(self, noise, eeg_features):\n",
    "        combined_input = torch.cat([noise, eeg_features], dim=1)\n",
    "        return self.main(combined_input)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee51616c-b257-4cae-aa2d-310937a54019",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Descriminator(nn.Module): \n",
    "    def __init__(self, channels=3): \n",
    "        super(Descriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(channels, 64, 4, 2, 1, bias=False), \n",
    "            nn.LeakyReLU(0.2, inplace=True), \n",
    "\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False), \n",
    "            nn.BatchNorm2d(128), \n",
    "            nn.LeakyReLU(0.2, inplace=True), \n",
    "            \n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False), \n",
    "            nn.BatchNorm2d(256), \n",
    "            nn.LeakyReLU(0.2, inplace=True), \n",
    "\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False), \n",
    "            nn.BatchNorm2d(512), \n",
    "            nn.LeakyReLU(0.2, inplace=True), \n",
    "\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img): \n",
    "        return self.main(img).view(-1, 1).squeeze(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cb365-9915-4f3a-afd4-6946979a0590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb3cb9-1dec-4a6a-9c4e-7a445954daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    def __init__(self, model, save_path='../models/eeg_classifier.pt', patience=5, tol=1e-3):\n",
    "        self.model = model\n",
    "        self.save_path = save_path\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.tol = tol\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, batch_val_loss):\n",
    "        if batch_val_loss < self.best_val_loss - self.tol:\n",
    "            torch.save(self.model.state_dict(), self.save_path)\n",
    "            self.best_val_loss = batch_val_loss\n",
    "            self.counter = 0\n",
    "            print(f'Validation Loss improved -> model saved to {self.save_path}')\n",
    "            \n",
    "        else:\n",
    "            if self.counter < self.patience: \n",
    "                self.counter += 1\n",
    "                print(f'No improvement in Val Loss. Counter: {self.counter}/{self.patience}')\n",
    "                \n",
    "            else: \n",
    "                self.early_stop = True\n",
    "                print(f\"Early Stopping triggered!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401a423-49b1-40f1-b535-4db7af34c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_name, train_loader, val_loader, epochs=20, lr=1e-2, device='cpu'): \n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.Tensor(train_cls_wts).to(device))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    writer = SummaryWriter(log_dir=f'../reports/runs/{model_name}')\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
    "    early_stopping = EarlyStopping(model, save_path=f'../models/{model_name}_v1_best.pth', patience=4)\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "        train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train Pass]', leave=True)\n",
    "\n",
    "        for batch_x, batch_y, lengths in train_bar: \n",
    "            batch_x, batch_y, lengths = batch_x.to(device), batch_y.to(device), lengths.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_preds = model(batch_x, lengths)\n",
    "\n",
    "            loss = criterion(y_preds, batch_y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * batch_x.size(0)\n",
    "            _, preds = torch.max(y_preds, 1)\n",
    "            train_correct += (preds == batch_y).sum().item()\n",
    "            train_total += batch_y.size(0)\n",
    "\n",
    "            train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_acc = train_correct / train_total\n",
    "        train_loss /= train_total\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "\n",
    "        val_bar = tqdm(val_loader, desc=f\"Epoch{epoch+1}/{epochs} [Val Pass]\", leave=True)\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            for batch_x, batch_y, lengths in val_bar:\n",
    "                batch_x, batch_y, lengths = batch_x.to(device), batch_y.to(device), lengths.to(device)\n",
    "\n",
    "                y_preds = model(batch_x, lengths)\n",
    "                loss = criterion(y_preds, batch_y)\n",
    "                \n",
    "                val_loss += loss.item() * batch_x.size(0)\n",
    "                _, preds = torch.max(y_preds, 1)\n",
    "                val_correct += (preds == batch_y).sum().item()\n",
    "                val_total += batch_y.size(0)\n",
    "\n",
    "                val_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss /= val_total\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "            \n",
    "\n",
    "        # logging\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}:\\nTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f} %\\nVal Loss: {val_loss:.3f} | Val Acc: {val_acc*100:.2f}\")\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc98eb7-1f94-448f-9631-a983d33d4c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_summary(model):\n",
    "    print('========================================= Model Summary ==============================================\\n')\n",
    "    print(f\"\\n{'='*55}\")\n",
    "    print(f\"{'| Parameter Name':31}|| Number of Parameters|\")\n",
    "    print(f\"{'='*55}\")\n",
    "    \n",
    "    total_params = 0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        print(f'| {name:30}|{param.numel():20} |')\n",
    "        print(f\"{'-'*55}\")\n",
    "        total_params += param.numel()\n",
    "        \n",
    "    print(f\"\\nTotal Parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9cb8d-ac5b-4ba4-a4ec-8b2d0877b6f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450a101a-3a4c-4e5b-85f0-4189cae1651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = EegLstm(input_dims=5, hidden_dims=128, num_layers=4, dropout=0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ffcf2-4219-4dd0-b84a-57ca835d803a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_summary(lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b77474-4ff5-4ad0-8f17-2cb024182b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'        \n",
    "# train_model(lstm_model, 'EEG_LSTM', train_loader, val_loader, 10, 1e-3, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc284f5f-0ff3-4928-9c02-e89f81e00640",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d998b-4dc9-44d3-a810-5c73cc5d3dee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurovision",
   "language": "python",
   "name": "neurovision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
