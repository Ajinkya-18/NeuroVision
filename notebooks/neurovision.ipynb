{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f68d0c-a42d-4ede-a02d-d2ea6dbf9275",
   "metadata": {},
   "source": [
    "# NeuroVision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72595744-4d1f-4a7a-b3fa-bb0f3aa81f6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1261d6a6-b4c8-4b94-be10-b6d3fb8ef6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8032e90f-bd97-42fe-b7d9-3d37ff56fd9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162949c-6fe9-43c2-a775-7dbf886ab75a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9fbc4228-6ab9-4fb4-8dbc-13d2b07e5d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read the dir contents of dataset folder and segregate them \n",
    "# into n separate classes.\n",
    "def create_dataset_folders(metadata_file:str, csv_dir:str, output_dir:str):\n",
    "    class_id_to_folder = {}\n",
    "\n",
    "    with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "\n",
    "            label_str, _, class_id = parts\n",
    "            # print(label_str, class_id)\n",
    "            first_label = label_str.split(',')[0].strip()\n",
    "            # print(first_label)\n",
    "            class_id_to_folder[class_id] = first_label\n",
    "\n",
    "        count = 0\n",
    "        for filename in os.listdir(csv_dir):\n",
    "            if not filename.endswith('.csv'):\n",
    "                continue\n",
    "\n",
    "            class_id = filename.split('_')[3]\n",
    "\n",
    "            folder_name = class_id_to_folder.get(class_id)\n",
    "            print(folder_name)\n",
    "\n",
    "            if not folder_name:\n",
    "                print(f'Unknown class id: {class_id}')\n",
    "                continue\n",
    "\n",
    "            safe_folder = folder_name.replace('/', '_').replace('\\\\', '_').strip()\n",
    "\n",
    "            dest_folder = os.path.join(output_dir, safe_folder)\n",
    "            os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "            src_path = os.path.join(csv_dir, filename)\n",
    "            dst_path = os.path.join(dest_folder, filename)\n",
    "\n",
    "            # print(f\"Move: {src_path} to {dst_path}\")\n",
    "            count+=1\n",
    "            print(count)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0ee6e-277d-43c4-8269-88ef54a61c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create_dataset_folders('../data/WordReport-v1.04.txt', \n",
    "#                        '../data/MindBigData-Imagenet', \n",
    "#                        '../data/Segregated_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaa17b9-c502-45b8-b160-811f7d265d8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('../data/Segregated_Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a4f18-0cbf-451e-be8c-1aa156eff8a7",
   "metadata": {},
   "source": [
    "## Dataset Processing for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6f7ba77-0e7b-46c4-9823-85ed74ec2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027fe9b8-8ee9-4f76-b0b0-20f528f20261",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, root_dir, samples, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.samples)          \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.samples[idx]\n",
    "\n",
    "        df = pd.read_csv(file_path, header=None, index_col=0)\n",
    "        eeg_data = torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "        if eeg_data.shape[0] < eeg_data.shape[1]:\n",
    "            eeg_data = eeg_data.T\n",
    "\n",
    "        if self.transform:\n",
    "            eeg_data = self.transform(eeg_data)\n",
    "\n",
    "        return eeg_data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4342db-dfec-4a91-bd75-848017a33149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(root_dir, val_ratio=0.2, random_state=42): \n",
    "    class_names = sorted(os.listdir(root_dir))\n",
    "    class_to_idx = {cls:idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "    all_samples = []\n",
    "    all_labels = []\n",
    "\n",
    "    for cls in class_names:\n",
    "        cls_dir = os.path.join(root_dir, cls)\n",
    "        \n",
    "        for fname in os.listdir(cls_dir): \n",
    "            if fname.endswith('.csv'):\n",
    "                path = os.path.join(cls_dir, fname)\n",
    "                all_samples.append((path, class_to_idx[cls]))\n",
    "                all_labels.append(class_to_idx[cls])\n",
    "\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        list(range(len(all_samples))), \n",
    "        test_size=val_ratio, \n",
    "        random_state=random_state, \n",
    "        stratify=all_labels\n",
    "    )\n",
    "\n",
    "    train_samples = [all_samples[i] for i in train_idx]\n",
    "    val_samples = [all_samples[i] for i in val_idx]\n",
    "\n",
    "    train_dataset = EEGDataset(root_dir, train_samples)\n",
    "    val_dataset = EEGDataset(root_dir, val_samples)\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0696ba6-64c0-427e-895e-0dead7a43cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "\n",
    "    lengths = torch.tensor([seq.size(0) for seq in sequences], dtype=torch.long)\n",
    "    padded_seqs = pad_sequence(sequences, batch_first=True)\n",
    "\n",
    "    return padded_seqs, torch.tensor(labels), lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3aa364a-238c-4491-b180-38f91b9e998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = make_datasets('../data/Segregated_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17257081-7cf6-46c9-ab11-f4f30a81cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80a3a655-982f-4506-b3ef-3129d52c60c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 404, 5])\n",
      "tensor([471, 178, 497, 250, 518, 414, 150, 237, 518, 199, 236, 507, 533, 177,\n",
      "        525, 539,   6,   7,  35, 529, 368, 260, 515, 559,  20, 156, 209, 511,\n",
      "         36, 105, 268, 210])\n"
     ]
    }
   ],
   "source": [
    "x, y, lengths = next(iter(train_loader))\n",
    "\n",
    "print(x.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bc1dca2-767a-4455-bfb0-918e18fa2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('../data/Segregated_Dataset/accordion/MindBigData_Imagenet_Insight_n02672831_563_1_2136.csv', header=None, index_col=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83611cd6-9cd8-448d-9ce0-0e50cc436cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9df9cb8d-ac5b-4ba4-a4ec-8b2d0877b6f0",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6bc25e-5080-4a64-8186-5b9ba8a59dee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurovision",
   "language": "python",
   "name": "neurovision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
